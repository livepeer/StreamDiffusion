# StreamDiffusion IPAdapter img2img Configuration Example
# This demonstrates how to configure IPAdapter for image-to-image mode

# Base model configuration
model_id: "C:\\_dev\\comfy\\ComfyUI\\models\\checkpoints\\perfectPhotonPerfect_perfectPhotonV21.safetensors"
device: "cuda"
dtype: "float16"
width: 512
height: 512
mode: "img2img"  # Changed from txt2img to img2img

# StreamDiffusion parameters
t_index_list: [25, 32, 45]  # Different t_index_list for img2img (closer to img2img examples)
frame_buffer_size: 1
warmup: 10
acceleration: "tensorrt"
use_denoising_batch: true    # img2img typically uses denoising batch
cfg_type: "self"             # img2img uses "self" instead of "none"
seed: 42

engine_dir: "C:\\_dev\\comfy\\ComfyUI\\StreamDiffusion\\engines\\ipa"

# Text prompts (these will be combined with IPAdapter style conditioning)
prompt: "masterpiece, high detail, 8k"
negative_prompt: "blurry, horror, worst quality, low quality"
num_inference_steps: 50
guidance_scale: 1.0
delta: 1  # Delta parameter for img2img

use_controlnet: false

# IPAdapter configuration
ipadapters:
  # Explicit model paths (required)
  - ipadapter_model_path: "h94/IP-Adapter/models/ip-adapter-plus_sd15.safetensors"
    image_encoder_path: "h94/IP-Adapter/models/image_encoder"
    style_image: "../../images/inputs/gold.jpg"
    scale: 0.70
    enabled: true
    
  # For SDXL models:
  # - ipadapter_model_path: "h94/IP-Adapter/sdxl_models/ip-adapter-plus-face_sdxl_vit-h.safetensors"
  #   image_encoder_path: "h94/IP-Adapter/sdxl_models/image_encoder"
  #   style_image: "../../images/inputs/gold.jpg"
  #   scale: 0.70
  #   enabled: true

# python ipadapter_img2img_config_example.py --config .\ipadapter_img2img_config_example.yaml --input-image  ..\..\..\input\hand_up512.png